version: 2.1

orbs:
  node: circleci/node@4.1.0

# define snippets that will be reused
aliases:
  # use a base image running node v12 with chrome/firefox browsers preinstalled
  - &docker
    - image: circleci/node:12-browsers
    # ensure local timezone set to UTC
  - &environment
    TZ: /usr/share/zoneinfo/UTC

    # These can also be created as commands, but slighly tidier to just use inline
  - &restore_yarn_cache
    restore_cache:
      name: Restore yarn cache
      keys:
        # https://circleci.com/docs/2.0/caching/
        # when lock file changes, use increasingly general patterns to restore cache
        # NOTE - this will change if migrating to yarn v2 in the future
        - yarn-packages-v1-{{ .Branch }}-{{ checksum "yarn.lock" }}
        - yarn-packages-v1-{{ .Branch }}-
        - yarn-packages-v1-
  - &install_yarn
    run:
      name: Install Packages
      command: yarn --frozen-lockfile --cache-folder ~/.cache/yarn
  - &save_yarn_cache
    save_cache:
      paths:
        - ~/.cache/yarn
      key: yarn-packages-v1-{{ .Branch }}-{{ checksum "yarn.lock" }}

  - &TEST_PARALLELISM 4

jobs:
  setup:
    docker: *docker
    environment: *environment
    steps:
      - checkout
      - *restore_yarn_cache
      - *install_yarn
      - *save_yarn_cache
  build:
    docker: *docker
    environment: *environment
    steps:
      # whilst checkout-install could be persisted from previous step, that is less efficient than just using caching
      - checkout
      # restore/install/save can all be done with a single circle-ci orb, but less flexible and breaks intellisense
      - *restore_yarn_cache
      - *install_yarn
      - *save_yarn_cache
      - run:
          command: npm run build
      # - persist_to_workspace:
      #     root: .
      #     paths:
      #       - package.json
      #       - build
      # - store_artifacts:
      #     path: build
      #     destination: build

# This describes the main order of job executions
workflows:
  version: 2
  build_and_test:
    # by default jobs will run concurrently, so specify requires if want to run sequentially
    jobs:
      - setup
      - build:
          requires:
            - setup
#   RELEASE_CHANNEL_stable_yarn_build:
#     docker: *docker
#     environment: *environment
#     parallelism: *TEST_PARALLELISM
#     steps:
#       - checkout
#       - run: yarn workspaces info | head -n -1 > workspace_info.txt
#       - *restore_node_modules
#       - run:
#           environment:
#             RELEASE_CHANNEL: stable
#           command: |
#             ./scripts/circleci/add_build_info_json.sh
#             ./scripts/circleci/update_package_versions.sh
#             yarn build
#       - run: echo "stable" >> build/RELEASE_CHANNEL
#       - persist_to_workspace:
#           root: build
#           paths:
#             - RELEASE_CHANNEL
#             - facebook-www
#             - facebook-react-native
#             - facebook-relay
#             - node_modules
#             - react-native
#             - dist
#             - sizes/*.json

#   yarn_build:
#     docker: *docker
#     environment: *environment
#     parallelism: 20
#     steps:
#       - checkout
#       - run: yarn workspaces info | head -n -1 > workspace_info.txt
#       - *restore_node_modules
#       - run:
#           environment:
#             RELEASE_CHANNEL: experimental
#           command: |
#             ./scripts/circleci/add_build_info_json.sh
#             ./scripts/circleci/update_package_versions.sh
#             yarn build
#       - run: echo "experimental" >> build/RELEASE_CHANNEL
#       - persist_to_workspace:
#           root: build
#           paths:
#             - RELEASE_CHANNEL
#             - facebook-www
#             - facebook-react-native
#             - facebook-relay
#             - node_modules
#             - react-native
#             - dist
#             - sizes/*.json

#   yarn_build_combined:
#     docker: *docker
#     environment: *environment
#     parallelism: 40
#     steps:
#       - checkout
#       - run: yarn workspaces info | head -n -1 > workspace_info.txt
#       - *restore_node_modules
#       - run: yarn build-combined
#       - persist_to_workspace:
#           root: .
#           paths:
#             - build2

#   get_base_build:
#     docker: *docker
#     environment: *environment
#     steps:
#       - checkout
#       - run: yarn workspaces info | head -n -1 > workspace_info.txt
#       - *restore_node_modules
#       - run:
#           name: Download artifacts for base revision
#           command: |
#               git fetch origin master
#               cd ./scripts/release && yarn && cd ../../
#               scripts/release/download-experimental-build.js --commit=$(git merge-base HEAD origin/master)
#               mv ./build2 ./base-build
#       - persist_to_workspace:
#           root: .
#           paths:
#             - base-build

#   process_artifacts_combined:
#     docker: *docker
#     environment: *environment
#     steps:
#       - checkout
#       - attach_workspace:
#           at: .
#       - run: yarn workspaces info | head -n -1 > workspace_info.txt
#       - *restore_node_modules
#       - run: echo "<< pipeline.git.revision	>>" >> build2/COMMIT_SHA
#         # Compress build directory into a single tarball for easy download
#       - run: tar -zcvf ./build2.tgz ./build2
#       - store_artifacts:
#           path: ./build2.tgz

#   sizebot:
#     docker: *docker
#     environment: *environment
#     steps:
#       - checkout
#       - attach_workspace:
#           at: .
#       - run: echo "<< pipeline.git.revision	>>" >> build2/COMMIT_SHA
#       - run: yarn workspaces info | head -n -1 > workspace_info.txt
#       - *restore_node_modules
#       - run:
#           command: node ./scripts/tasks/danger

#   build_devtools_and_process_artifacts:
#     docker: *docker
#     environment: *environment
#     steps:
#       - checkout
#       - attach_workspace: *attach_workspace
#       - run: yarn workspaces info | head -n -1 > workspace_info.txt
#       - *restore_yarn_cache
#       - *restore_node_modules
#       - run:
#           name: Install Packages
#           command: yarn --frozen-lockfile --cache-folder ~/.cache/yarn
#       - run:
#           environment:
#             RELEASE_CHANNEL: experimental
#           command: ./scripts/circleci/pack_and_store_devtools_artifacts.sh
#       - store_artifacts:
#           path: ./build/devtools.tgz

#   build_devtools_scheduling_profiler:
#     docker: *docker
#     environment: *environment
#     steps:
#       - checkout
#       - attach_workspace: *attach_workspace
#       - run: yarn workspaces info | head -n -1 > workspace_info.txt
#       - *restore_yarn_cache
#       - *restore_node_modules
#       - run:
#           name: Install Packages
#           command: yarn --frozen-lockfile --cache-folder ~/.cache/yarn
#       - run:
#           name: Build and archive
#           command: |
#             mkdir -p build/devtools
#             cd packages/react-devtools-scheduling-profiler
#             yarn build
#             cd dist
#             tar -zcvf ../../../build/devtools-scheduling-profiler.tgz .
#       - store_artifacts:
#           path: ./build/devtools-scheduling-profiler.tgz
#       - persist_to_workspace:
#           root: packages/react-devtools-scheduling-profiler
#           paths:
#             - dist

#   deploy_devtools_scheduling_profiler:
#     docker: *docker
#     environment: *environment
#     steps:
#       - checkout
#       - attach_workspace:
#           at: packages/react-devtools-scheduling-profiler
#       - run: yarn workspaces info | head -n -1 > workspace_info.txt
#       - *restore_node_modules
#       - run:
#           name: Deploy
#           command: |
#             cd packages/react-devtools-scheduling-profiler
#             yarn vercel deploy dist --prod --confirm --token $SCHEDULING_PROFILER_DEPLOY_VERCEL_TOKEN
#   yarn_lint_build:
#     docker: *docker
#     environment: *environment
#     steps:
#       - checkout
#       - attach_workspace: *attach_workspace
#       - run: yarn workspaces info | head -n -1 > workspace_info.txt
#       - *restore_node_modules
#       - run: yarn lint-build
#       - run: scripts/circleci/check_minified_errors.sh

#   RELEASE_CHANNEL_stable_yarn_lint_build:
#     docker: *docker
#     environment: *environment
#     steps:
#       - checkout
#       - attach_workspace: *attach_workspace
#       - run: yarn workspaces info | head -n -1 > workspace_info.txt
#       - *restore_node_modules
#       - run:
#           environment:
#             RELEASE_CHANNEL: stable
#           command: yarn lint-build
#       - run: scripts/circleci/check_minified_errors.sh

#   yarn_test:
#     docker: *docker
#     environment: *environment
#     parallelism: *TEST_PARALLELISM
#     parameters:
#       args:
#         type: string
#     steps:
#       - checkout
#       - run: yarn workspaces info | head -n -1 > workspace_info.txt
#       - *restore_node_modules
#       - run: yarn test <<parameters.args>> --ci

#   yarn_test_build:
#     docker: *docker
#     environment: *environment
#     parallelism: *TEST_PARALLELISM
#     parameters:
#       args:
#         type: string
#     steps:
#       - checkout
#       - attach_workspace:
#           at: .
#       - run: yarn workspaces info | head -n -1 > workspace_info.txt
#       - *restore_node_modules
#       - run: yarn test --build <<parameters.args>> --ci

#   RELEASE_CHANNEL_stable_yarn_test_dom_fixtures:
#     docker: *docker
#     environment: *environment
#     steps:
#       - checkout
#       - attach_workspace: *attach_workspace
#       - run: yarn workspaces info | head -n -1 > workspace_info.txt
#       - *restore_node_modules
#       - run:
#           name: Run DOM fixture tests
#           environment:
#             RELEASE_CHANNEL: stable
#           command: |
#             cd fixtures/dom
#             yarn --frozen-lockfile
#             yarn prestart
#             yarn test --maxWorkers=2
#   test_fuzz:
#     docker: *docker
#     environment: *environment
#     steps:
#       - checkout
#       - run: yarn workspaces info | head -n -1 > workspace_info.txt
#       - *restore_node_modules
#       - run:
#           name: Run fuzz tests
#           command: |
#             FUZZ_TEST_SEED=$RANDOM yarn test fuzz --ci
#             FUZZ_TEST_SEED=$RANDOM yarn test --prod fuzz --ci
#   publish_prerelease:
#     parameters:
#       commit_sha:
#         type: string
#       release_channel:
#         type: string
#       dist_tag:
#         type: string
#     docker: *docker
#     environment: *environment
#     steps:
#       - checkout
#       - run: yarn workspaces info | head -n -1 > workspace_info.txt
#       - *restore_node_modules
#       - run:
#           name: Run publish script
#           command: |
#             git fetch origin master
#             cd ./scripts/release && yarn && cd ../../
#             scripts/release/prepare-release-from-ci.js --skipTests -r << parameters.release_channel >> --commit=<< parameters.commit_sha >>
#             cp ./scripts/release/ci-npmrc ~/.npmrc
#             scripts/release/publish.js --ci --tags << parameters.dist_tag >>
#   # We don't always keep the reconciler forks in sync (otherwise it we wouldn't
#   # have forked it) but during periods when they are meant to be in sync, we
#   # use this job to confirm there are no differences.
#   sync_reconciler_forks:
#     docker: *docker
#     environment: *environment
#     steps:
#       - checkout
#       - run: yarn workspaces info | head -n -1 > workspace_info.txt
#       - *restore_node_modules
#       - run:
#           name: Confirm reconciler forks are the same
#           command: |
#             yarn replace-fork
#             git diff --quiet || (echo "Reconciler forks are not the same! Run yarn replace-fork. Or, if this was intentional, disable this CI check." && false)

#   experimental:
#     unless: << pipeline.parameters.prerelease_commit_sha >>
#     jobs:
#       - setup
#       - yarn_build:
#           requires:
#             - setup
#       - yarn_lint_build:
#           requires:
#             - yarn_build
#       - build_devtools_and_process_artifacts:
#           requires:
#             - yarn_build
#       - build_devtools_scheduling_profiler:
#           requires:
#             - yarn_build
#       - deploy_devtools_scheduling_profiler:
#           requires:
#             - build_devtools_scheduling_profiler
#           filters:
#             branches:
#               only:
#                 - master

#   # New workflow that will replace "stable" and "experimental"
#   build_and_test:
#     unless: << pipeline.parameters.prerelease_commit_sha >>
#     jobs:
#       - setup
#       - yarn_flow:
#           requires:
#             - setup
#       # NOTE: This job is only enabled when we want the forks to be in sync.
#       # When the forks intentionally diverge, comment out the job to disable it.
#       - sync_reconciler_forks:
#           requires:
#             - setup
#       - yarn_test:
#           requires:
#             - setup
#           matrix:
#             parameters:
#               args:
#                 # Intentionally passing these as strings instead of creating a
#                 # separate parameter per CLI argument, since it's easier to
#                 # control/see which combinations we want to run.
#                 - "-r=stable --env=development"
#                 - "-r=stable --env=production"
#                 - "-r=experimental --env=development"
#                 - "-r=experimental --env=production"
#                 - "-r=www-classic --env=development"
#                 - "-r=www-classic --env=production"
#                 - "-r=www-classic --env=development --variant"
#                 - "-r=www-classic --env=production --variant"
#                 - "-r=www-modern --env=development"
#                 - "-r=www-modern --env=production"
#                 - "-r=www-modern --env=development --variant"
#                 - "-r=www-modern --env=production --variant"

#                 # TODO: Test more persistent configurations?
#                 - '-r=stable --env=development --persistent'
#       - yarn_build_combined:
#           requires:
#             - setup
#       - process_artifacts_combined:
#           requires:
#             - yarn_build_combined
#       - yarn_test_build:
#           requires:
#             - yarn_build_combined
#           matrix:
#             parameters:
#               args:
#                 # Intentionally passing these as strings instead of creating a
#                 # separate parameter per CLI argument, since it's easier to
#                 # control/see which combinations we want to run.
#                 - "-r=stable --env=development"
#                 - "-r=stable --env=production"
#                 - "-r=experimental --env=development"
#                 - "-r=experimental --env=production"

#                 # Dev Tools
#                 - "--project=devtools -r=experimental"

#                 # TODO: Update test config to support www build tests
#                 # - "-r=www-classic --env=development"
#                 # - "-r=www-classic --env=production"
#                 # - "-r=www-classic --env=development --variant"
#                 # - "-r=www-classic --env=production --variant"
#                 # - "-r=www-modern --env=development"
#                 # - "-r=www-modern --env=production"
#                 # - "-r=www-modern --env=development --variant"
#                 # - "-r=www-modern --env=production --variant"

#                 # TODO: Test more persistent configurations?
#       - get_base_build:
#           filters:
#             branches:
#               ignore:
#                 - master
#           requires:
#             - setup
#       - sizebot:
#           filters:
#             branches:
#               ignore:
#                 - master
#           requires:
#             - get_base_build
#             - yarn_build_combined
#   fuzz_tests:
#     unless: << pipeline.parameters.prerelease_commit_sha >>
#     triggers:
#       - schedule:
#           # Fuzz tests run hourly
#           cron: "0 * * * *"
#           filters:
#             branches:
#               only:
#                 - master
#     jobs:
#       - setup
#       - test_fuzz:
#           requires:
#             - setup

#   # Used to publish a prerelease manually via the command line
#   publish_preleases:
#     when: << pipeline.parameters.prerelease_commit_sha >>
#     jobs:
#       - setup
#       - publish_prerelease:
#           name: Publish to Next channel
#           requires:
#             - setup
#           commit_sha: << pipeline.parameters.prerelease_commit_sha >>
#           release_channel: stable
#           dist_tag: next
#       - publish_prerelease:
#           name: Publish to Experimental channel
#           requires:
#             - setup
#           commit_sha: << pipeline.parameters.prerelease_commit_sha >>
#           release_channel: experimental
#           dist_tag: experimental

#   # Publishes on a cron schedule
#   publish_preleases_nightly:
#     unless: << pipeline.parameters.prerelease_commit_sha >>
#     triggers:
#       - schedule:
#           # At 10 minutes past 16:00 on Mon, Tue, Wed, Thu, and Fri
#           cron: "10 16 * * 1,2,3,4,5"
#           filters:
#             branches:
#               only:
#                 - master
#     jobs:
#       - setup
#       - publish_prerelease:
#           name: Publish to Next channel
#           requires:
#             - setup
#           commit_sha: master
#           release_channel: stable
#           dist_tag: next
#       - publish_prerelease:
#           name: Publish to Experimental channel
#           requires:
#             - setup
#           commit_sha: master
#           release_channel: experimental
#           dist_tag: experimental
